{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M3QD3ugjaxIN"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/HSE-LAMBDA/DeepGenerativeModels/blob/master/seminars/seminar-9/1.aae.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iiV4GELubv0j",
    "outputId": "e75ea300-e841-47dc-cbe4-56a49cf26cff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: comet-ml in /usr/local/lib/python3.7/dist-packages (3.3.4)\n",
      "Requirement already satisfied: wrapt>=1.11.2 in /usr/local/lib/python3.7/dist-packages (from comet-ml) (1.12.1)\n",
      "Requirement already satisfied: requests-toolbelt>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from comet-ml) (0.9.1)\n",
      "Requirement already satisfied: everett[ini]>=1.0.1; python_version >= \"3.0\" in /usr/local/lib/python3.7/dist-packages (from comet-ml) (1.0.3)\n",
      "Requirement already satisfied: nvidia-ml-py3>=7.352.0 in /usr/local/lib/python3.7/dist-packages (from comet-ml) (7.352.0)\n",
      "Requirement already satisfied: netifaces>=0.10.7 in /usr/local/lib/python3.7/dist-packages (from comet-ml) (0.10.9)\n",
      "Requirement already satisfied: jsonschema!=3.1.0,>=2.6.0 in /usr/local/lib/python3.7/dist-packages (from comet-ml) (2.6.0)\n",
      "Requirement already satisfied: requests>=2.18.4 in /usr/local/lib/python3.7/dist-packages (from comet-ml) (2.23.0)\n",
      "Requirement already satisfied: dulwich>=0.20.6; python_version >= \"3.0\" in /usr/local/lib/python3.7/dist-packages (from comet-ml) (0.20.19)\n",
      "Requirement already satisfied: wurlitzer>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from comet-ml) (2.0.1)\n",
      "Requirement already satisfied: websocket-client>=0.55.0 in /usr/local/lib/python3.7/dist-packages (from comet-ml) (0.57.0)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from comet-ml) (1.15.0)\n",
      "Requirement already satisfied: configobj; extra == \"ini\" in /usr/local/lib/python3.7/dist-packages (from everett[ini]>=1.0.1; python_version >= \"3.0\"->comet-ml) (5.0.6)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.18.4->comet-ml) (2.10)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.18.4->comet-ml) (1.24.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.18.4->comet-ml) (2020.12.5)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.18.4->comet-ml) (3.0.4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COMET INFO: Experiment is live on comet.ml https://www.comet.ml/holybayes/hse-gans-aae/757e0e895d784a018cff22306d7fb4f4\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!pip install comet-ml\n",
    "\n",
    "# import comet_ml in the top of your file\n",
    "from comet_ml import Experiment\n",
    "    \n",
    "# Add the following code anywhere in your machine learning file\n",
    "experiment = Experiment(api_key=\"lODeHEtCf7XLaV6DJrOfugNcA\",\n",
    "                        project_name=\"hse-gans-aae\", workspace=\"holybayes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "In3JGXgmaxIT"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.autograd as autograd\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import os\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "s6BdrapvaxIb",
    "outputId": "a834646f-e6b1-4707-bb48-9c7adde347a9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:279: UserWarning: The use of the transforms.Scale transform is deprecated, please use transforms.Resize instead.\n",
      "  warnings.warn(\"The use of the transforms.Scale transform is deprecated, \" +\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "batch_size = 256\n",
    "\n",
    "transform = transforms.Compose([\n",
    "        # transforms.CenterCrop(160),\n",
    "        transforms.Scale(64),\n",
    "        transforms.ToTensor(),\n",
    "         #transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
    "    ])\n",
    "\n",
    "dataset = datasets.CIFAR10('./data/',transform=transform,download=True)\n",
    "data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=20, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "FzL9aTSvaxIh"
   },
   "outputs": [],
   "source": [
    "cuda = True\n",
    "cnt = 0\n",
    "lr = 1e-4\n",
    "\n",
    "nc = 3 # number of channels\n",
    "nz = 64 # size of latent vector\n",
    "ngf = 64 # decoder (generator) filter factor\n",
    "ndf = 64 # encoder filter factor\n",
    "h_dim = 128 # discriminator hidden size\n",
    "lam = 1 # regulization coefficient\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.main = [\n",
    "            # input is Z, going into a convolution\n",
    "            nn.ConvTranspose2d(     nz, ngf * 8, 4, 1, 0, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 8),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (ngf*8) x 4 x 4\n",
    "            nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 4),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (ngf*4) x 8 x 8\n",
    "            nn.ConvTranspose2d(ngf * 4, ngf * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 2),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (ngf*2) x 16 x 16\n",
    "            nn.ConvTranspose2d(ngf * 2,     ngf, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (ngf) x 32 x 32\n",
    "            nn.ConvTranspose2d(    ngf,      nc, 4, 2, 1, bias=False),\n",
    "            nn.Sigmoid()\n",
    "            # state size. (nc) x 64 x 64\n",
    "        ]\n",
    "        for idx, module in enumerate(self.main):\n",
    "            self.add_module(str(idx), module)\n",
    "\n",
    "    def forward(self, x):\n",
    "        for layer in self.main:\n",
    "            x = layer(x)\n",
    "        return x\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.main = [\n",
    "            # input is (nc) x 64 x 64\n",
    "            nn.Conv2d(nc, ndf, 4, 2, 1, bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf) x 32 x 32\n",
    "            nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 2),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf*2) x 16 x 16\n",
    "            nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 4),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf*4) x 8 x 8\n",
    "            nn.Conv2d(ndf * 4, ndf * 8, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 8),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf*8) x 4 x 4\n",
    "            nn.Conv2d(ndf * 8, nz, 4, 1, 0, bias=False),\n",
    "        ]\n",
    "\n",
    "        for idx, module in enumerate(self.main):\n",
    "            self.add_module(str(idx), module)\n",
    "\n",
    "    def forward(self, x):\n",
    "        for layer in self.main:\n",
    "            x = layer(x)\n",
    "        return x\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.main = [\n",
    "            nn.Linear(nz, h_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(h_dim, 1),\n",
    "            nn.Sigmoid()\n",
    "        ]\n",
    "        for idx, module in enumerate(self.main):\n",
    "            self.add_module(str(idx), module)\n",
    "    def forward(self, x):\n",
    "        for layer in self.main:\n",
    "            x = layer(x)\n",
    "        return x\n",
    "\n",
    "Q = Encoder().to(device)\n",
    "P = Decoder().to(device)\n",
    "D = Discriminator().to(device)\n",
    "\n",
    "def reset_grad():\n",
    "    Q.zero_grad()\n",
    "    P.zero_grad()\n",
    "    D.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "i6qk1b1naxIo",
    "outputId": "c6e46509-97c7-4529-c78e-d651cb42e1ac"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:70: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n"
     ]
    }
   ],
   "source": [
    "Q_solver = optim.Adam(Q.parameters(), lr=lr)\n",
    "P_solver = optim.Adam(P.parameters(), lr=lr)\n",
    "D_solver = optim.Adam(D.parameters(), lr=lr*0.1)\n",
    "\n",
    "for it in range(100000):\n",
    "\n",
    "    for batch_idx, batch_item in enumerate(data_loader):\n",
    "        #X = sample_X(mb_size)\n",
    "        \"\"\" Reconstruction phase \"\"\"\n",
    "        X = batch_item[0].to(device)\n",
    "\n",
    "        z_sample = Q(X)\n",
    "\n",
    "        X_sample = P(z_sample)\n",
    "        recon_loss = F.mse_loss(X_sample, X)\n",
    "\n",
    "        recon_loss.backward()\n",
    "        P_solver.step()\n",
    "        Q_solver.step()\n",
    "        reset_grad()\n",
    "\n",
    "        \"\"\" Regularization phase \"\"\"\n",
    "        # Discriminator\n",
    "        for _ in range(5):\n",
    "            z_real = torch.randn(batch_size, nz).to(device)\n",
    "            \n",
    "            z_fake = Q(X).view(batch_size,-1)\n",
    "\n",
    "            D_real = D(z_real)\n",
    "            D_fake = D(z_fake)\n",
    "\n",
    "            #D_loss = -torch.mean(torch.log(D_real) + torch.log(1 - D_fake))\n",
    "            D_loss = -(torch.mean(D_real) - torch.mean(D_fake))\n",
    "\n",
    "            D_loss.backward()\n",
    "            D_solver.step()\n",
    "\n",
    "            # Weight clipping\n",
    "            for p in D.parameters():\n",
    "                p.data.clamp_(-0.01, 0.01)\n",
    "\n",
    "            reset_grad()\n",
    "\n",
    "        # Generator\n",
    "        z_fake = Q(X).view(batch_size,-1)\n",
    "        D_fake = D(z_fake)\n",
    "\n",
    "        #G_loss = -torch.mean(torch.log(D_fake))\n",
    "        G_loss = -torch.mean(D_fake)\n",
    "\n",
    "        G_loss.backward()\n",
    "        Q_solver.step()\n",
    "        reset_grad()\n",
    "\n",
    "        experiment.log_metrics({'D_loss': D_loss.item(), 'G_loss': G_loss.item(), 'recon_loss': recon_loss.item()}, \n",
    "                               step=batch_idx, epoch=it)\n",
    "\n",
    "        # Print and plot every now and then\n",
    "        if batch_idx % 100 == 0:\n",
    "\n",
    "            z_real = z_real.unsqueeze(2).unsqueeze(3) # add 2 dimensions\n",
    "            if cnt % 2 == 0:\n",
    "                samples = P(z_real) # Generated\n",
    "            else:\n",
    "                samples = X_sample # Reconstruction\n",
    "            #samples = X_sample\n",
    "            samples = samples.cpu()\n",
    "            samples = samples.data.numpy()[:16]\n",
    "\n",
    "            plt.figure(figsize=(4, 4))\n",
    "            gs = gridspec.GridSpec(4, 4)\n",
    "            gs.update(wspace=0.05, hspace=0.05)\n",
    "\n",
    "            for i, sample in enumerate(samples):\n",
    "                ax = plt.subplot(gs[i])\n",
    "                plt.axis('off')\n",
    "                ax.set_xticklabels([])\n",
    "                ax.set_yticklabels([])\n",
    "                ax.set_aspect('equal')\n",
    "                sample = np.swapaxes(sample,0,2)\n",
    "                plt.imshow(sample)\n",
    "\n",
    "            experiment.log_figure('samples', figure=plt, step=cnt)\n",
    "            \n",
    "            cnt += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4M_O_VeJm1hH"
   },
   "outputs": [],
   "source": [
    "samples[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vpBzPu1pcNEh"
   },
   "outputs": [],
   "source": [
    "from torchvision.utils import make_grid\n",
    "plt.imshow(make_grid(torch.from_numpy(samples), 4).permute(1,2,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6ccBLmi3mblN"
   },
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "1.aae.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
